{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64b2b9d1",
   "metadata": {},
   "source": [
    "# SQL and Pandas fun using rdkit generated structures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93419288",
   "metadata": {},
   "source": [
    "This notebook is inspired by the work of Elholm et al. (2022) DOI: 10.1039/d2cp03032b from the group of Kasper Moth-Poulsen working on molecular solar thermal energy storage. Here, the python packages smilescombine, rdkit and ase are used for chemical calculations.\n",
    "The code for python to sql conversions is based on the tutorial by Craig Dickson and uses a MySQL Server."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efcfea1",
   "metadata": {},
   "source": [
    "More Scientific Background: doi: 10.1021/acs.jcim.1c00256. Epub 2021 Jun 23\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c9e187",
   "metadata": {},
   "source": [
    "## installation of required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84009779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### installation of chemical libraries:\n",
    "# for rdkit see: https://www.rdkit.org/docs/GettingStartedInPython.html\n",
    "# for ase  see: https://wiki.fysik.dtu.dk/ase/index.html\n",
    "# further inspirations: https://peterschindler.github.io/\n",
    "\n",
    "\n",
    "#! conda update -n base -c defaults conda\n",
    "#! conda create -n rdkit -y\n",
    "! conda activate rdkit \n",
    "#! conda install -c conda-forge rdkit -y \n",
    "\n",
    "\n",
    "#! pip install scipy --upgrade --user\n",
    "#! pip install --user smilescombine\n",
    "#! conda install matplotlib\n",
    "#! pip install --upgrade --user ase\n",
    "\n",
    "#conda deactivate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "450440c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### installation of sql requirements and pandas\n",
    "\n",
    "# see: https://www.freecodecamp.org/news/connect-python-with-sql/\n",
    "# and: https://realpython.com/python-sql-libraries/\n",
    "\n",
    "#! pip install mysql-connector-python\n",
    "#! pip install pandas\n",
    "#! pip install pandarallel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eeb54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22ea8f5",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eebaf16",
   "metadata": {},
   "source": [
    "## Let's start with defining the SQL/Python commands and connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acba438",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c486cc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### connecting to server\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "def create_server_connection(host_name, user_name, user_password):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=host_name,\n",
    "            user=user_name,\n",
    "            passwd=user_password\n",
    "        )\n",
    "        print(\"MySQL Database connection successful\")\n",
    "    except Error as err:\n",
    "        print(f\"Error: '{err}'\")\n",
    "\n",
    "    return connection\n",
    "\n",
    "pw = \n",
    "\n",
    "connection = create_server_connection(\"localhost\", \"root\", pw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a3893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating the database\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "def create_database(connection, query):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        print(\"Database created successfully\")\n",
    "    except Error as err:\n",
    "        print(f\"Error: '{err}'\")\n",
    "        \n",
    "create_database_query= 'CREATE DATABASE substituents'\n",
    "create_database(connection, create_database_query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5740193",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating connection to specific database\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "def create_db_connection(host_name, user_name, user_password, db_name):\n",
    "    connection = None\n",
    "    try:\n",
    "        connection = mysql.connector.connect(\n",
    "            host=host_name,\n",
    "            user=user_name,\n",
    "            passwd=user_password,\n",
    "            database=db_name\n",
    "        )\n",
    "        print(\"MySQL Database connection successful\")\n",
    "    except Error as err:\n",
    "        print(f\"Error: '{err}'\")\n",
    "\n",
    "    return connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62905f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "### creating a query execution function\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "def execute_query(connection, query):\n",
    "    cursor = connection.cursor(buffered=True)\n",
    "    try:\n",
    "        cursor.execute(query)\n",
    "        connection.commit()\n",
    "        print(\"Query successful\")\n",
    "    except Error as err:\n",
    "        print(f\"Error: '{err}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2ea9e0",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e82500e7",
   "metadata": {},
   "source": [
    "## Let's create the SQL library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981c106d",
   "metadata": {},
   "source": [
    "Architecture of simple database:\n",
    "Note: in the script there will be mentioned changes to the original database that were used for an original design that isn't used anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a7fb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create the substituents table\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "create_substituent_table = \"\"\"\n",
    "CREATE TABLE substituents (\n",
    "  substituent_id VARCHAR(100) NOT NULL,\n",
    "  smiles VARCHAR(500) NOT NULL,\n",
    "  atomseq VARCHAR(100) NOT NULL,\n",
    "  numconf INT NOT NULL,\n",
    "  numclust INT NOT NULL,\n",
    "  lowest_energy INT NOT NULL\n",
    "  );\n",
    " \"\"\"\n",
    "\n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db) # Connect to the Database\n",
    "execute_query(connection, create_substituent_table) # Execute our defined query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3428633",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create the conformers table\n",
    "# note this first definition contains a mistake that was maintained for learning purposes (see below)\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "create_conformers_table = \"\"\"\n",
    "CREATE TABLE conformers (\n",
    "  substituent_id VARCHAR(100) NOT NULL,\n",
    "  atomseq VARCHAR(100) NOT NULL,\n",
    "  positions VARCHAR(4000) NOT NULL,\n",
    "  cluster_no VARCHAR(3) NOT NULL,\n",
    "  conformer_num VARCHAR(4) NOT NULL,\n",
    "  energies INT NOT NULL\n",
    "  );\n",
    " \"\"\"\n",
    "\n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db) # Connect to the Database\n",
    "execute_query(connection, create_conformers_table) # Execute our defined query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fe319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create the clusters table\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "create_clusters_table = \"\"\"\n",
    "CREATE TABLE clusters (\n",
    "  substituent_id VARCHAR(100) NOT NULL,\n",
    "  clustID VARCHAR(50) NOT NULL,\n",
    "  clust_le INT NOT NULL,\n",
    "  clust_ae INT NOT NULL,\n",
    "  clust_me INT NOT NULL\n",
    "  );\n",
    " \"\"\"\n",
    "\n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db) # Connect to the Database\n",
    "execute_query(connection, create_clusters_table) # Execute our defined query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a04322",
   "metadata": {},
   "outputs": [],
   "source": [
    "### additionally one could define the relationships between tables but we won't do it here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52ac0201",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636991eb",
   "metadata": {},
   "source": [
    "## Define commands how to populate the table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "876c435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "def execute_list_query(connection, sql, val):\n",
    "    cursor = connection.cursor()\n",
    "    try:\n",
    "        cursor.executemany(sql, val)\n",
    "        connection.commit()\n",
    "        print(\"Query successful\")\n",
    "    except Error as err:\n",
    "        print(f\"Error: '{err}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1c8984",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f63c79",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49bc0ac8",
   "metadata": {},
   "source": [
    "## Let's start with the actual Chemistry in rdkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03055322",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Construct substituent library according to: https://github.com/LiamWilbraham/smilescombine\n",
    "# alternative way: https://iwatobipen.wordpress.com/2021/06/06/generate-all-combinations-of-rgroups-from-molecules-rdkit-chemoinformatics/\n",
    "# smile of nbd reads by the way as:\n",
    "# NBD = Cc1cc(C)cc(C)c1C2=CC3C=CC2C3\n",
    "\n",
    "from smilescombine import Combiner\n",
    "from rdkit import Chem\n",
    "#from rdkit.Chem import Draw\n",
    "#from rdkit.Chem.Draw import IPythonConsole\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "IPythonConsole.drawOptions.minFontSize = 10\n",
    "IPythonConsole.molSize = 350,300\n",
    "\n",
    "# m = Chem.MolFromSmiles('Cc1cc(C)cc(C)c1C2=CC3C=CC2C3')\n",
    "# s = Chem.MolToSmiles(m)\n",
    "# print(s) #-> Cc1cc(C)c(C2=CC3C=CC2C3)c(C)c1 ; C(Br)c1cc(C)c(C2=C(Br)C3C=CC2C3)c(C)(Br)c1\n",
    "\n",
    "substituents = ['(CN)', '(N(=O)(=O))', '(CO)', '(Cl)', '(F)', '(C(=C(CN)(CN)))', '(OCC)', '(C)']\n",
    "\n",
    "skeleton = Combiner('C(Br)c1cc(C(Br))c(C2=C(Br)C3C=CC2C3)c(C(Br))c1', substituents, nmax=4, nconnect=0, auto_placement=False)\n",
    "skeleton.combine_substituents()\n",
    "\n",
    "# extract smiles into pandas data frame\n",
    "skeleton2 = skeleton.combinations \n",
    "initial_df = pd.DataFrame({'smiles':skeleton2})\n",
    "\n",
    "# add id's\n",
    "initial_df['num'] = np.arange(initial_df.shape[0])\n",
    "\n",
    "def onesizenum(num):\n",
    "    padding = 4\n",
    "    str(num).zfill(padding)\n",
    "    return num\n",
    "\n",
    "initial_df['num_l'] = initial_df.num.apply(onesizenum)\n",
    "\n",
    "initial_df[\"id_list\"] = initial_df['num_l'].astype(str) +\"_\"+\"substituent\"\n",
    "initial_df = initial_df.drop('num_l', axis=1)\n",
    "initial_df = initial_df.drop('num', axis=1)\n",
    "\n",
    "# convert with numpy\n",
    "columns = initial_df[[\"id_list\", \"smiles\"]]\n",
    "arr1 = [tuple(r) for r in columns.to_numpy()]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25a57e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### insert smiles and ID's into substituent table\n",
    "\n",
    "# change type of data if needed:\n",
    "#improve = '''\n",
    "#    ALTER TABLE substituents MODIFY substituent_id VARCHAR(100);\n",
    "#    '''\n",
    "    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")\n",
    "\n",
    "# allow for empty cells if needed -> see here: https://stackoverflow.com/questions/15438840/mysql-error-1364-field-doesnt-have-a-default-values\n",
    "#improve2 = '''\n",
    "#    SET GLOBAL sql_mode='';\n",
    "#    '''\n",
    "    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve2)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")\n",
    "\n",
    "# do the actual insertion\n",
    "sql_1 = '''\n",
    "    INSERT INTO substituents (substituent_id, smiles) \n",
    "    VALUES (%s, %s)\n",
    "    '''\n",
    "    \n",
    "val_1 = arr1\n",
    "\n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "execute_list_query(connection, sql_1, val_1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b4085",
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate 3D conformers\n",
    "# from: https://greglandrum.github.io/rdkit-blog/posts/2023-02-04-working-with-conformers.html\n",
    "# and: https://patwalters.github.io/practicalcheminformatics/\n",
    "# scientific background: https://rdkit.org/UGM/2012/Ebejer_20110926_RDKit_1stUGM.pdf\n",
    "# this can take a while -> for 50 conformers (3645 substituents) it took 50 minutes \n",
    "\n",
    "import rdkit\n",
    "from rdkit.Chem import AllChem\n",
    "from rdkit import Chem\n",
    "#from rdkit.Chem.Draw import IPythonConsole\n",
    "#IPythonConsole.ipython_3d = True\n",
    "#import py3Dmol\n",
    "#from rdkit.Chem import rdDepictor\n",
    "#from rdkit.Chem import rdDistGeom\n",
    "\n",
    "import pandas\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "def generateconformations(m):\n",
    "    mol = Chem.MolFromSmiles(m)\n",
    "    mol = Chem.AddHs(mol)\n",
    "    ids=AllChem.EmbedMultipleConfs(mol, numConfs=numConfs, maxAttempts=maxAttempts, useRandomCoords=useRandomCoords, pruneRmsThresh=pruneRmsThresh, useExpTorsionAnglePrefs=useExpTorsionAnglePrefs, useBasicKnowledge=useBasicKnowledge, enforceChirality=enforceChirality, numThreads=4)\n",
    "    return mol\n",
    "\n",
    "# these variables need to be adjusted for molecule for which conformers are to be generated\n",
    "# for example: https://github.com/rdkit/rdkit/discussions/5841\n",
    "# variables can be looked up here: https://www.rdkit.org/docs/source/rdkit.Chem.rdDistGeom.html\n",
    "numConfs = 50\n",
    "maxAttempts = 10\n",
    "pruneRmsThresh = 0.5\n",
    "useExpTorsionAnglePrefs = True\n",
    "useBasicKnowledge = False\n",
    "enforceChirality = True\n",
    "useRandomCoords = True\n",
    "\n",
    "# in case, you want to test it on a subset first:\n",
    "df_sh = initial_df.sample(frac =1)\n",
    "\n",
    "df_sh['confMOL'] = df_sh.smiles.progress_apply(generateconformations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39bb867",
   "metadata": {},
   "outputs": [],
   "source": [
    "### check how many conformers were generated\n",
    "# alternative program to generate conformers: https://open-babel.readthedocs.io/en/latest/3DStructureGen/multipleconformers.html\n",
    "# see for alternative: https://github.com/rdkit/rdkit/discussions/6065\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "#from rdkit.Chem.Draw import IPythonConsole\n",
    "#IPythonConsole.ipython_3d = True\n",
    "#from rdkit.Chem import rdDepictor\n",
    "#from rdkit.Chem import rdDistGeom\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# check results:\n",
    "#df_sh.head()\n",
    "\n",
    "#esomeprazole.GetNumConformers()\n",
    "\n",
    "def getnumconf(mol):\n",
    "    num = mol.GetNumConformers()\n",
    "    return num\n",
    "\n",
    "df_sh['numconf'] = df_sh.confMOL.apply(getnumconf)\n",
    "\n",
    "# check results\n",
    "\n",
    "df_sh['numconf'].hist(bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de397a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "### improve conformers\n",
    "# takes around 3 minutes\n",
    "\n",
    "import rdkit\n",
    "from rdkit.Chem import rdForceFieldHelpers\n",
    "from rdkit import Chem\n",
    "#from rdkit.Chem.Draw import IPythonConsole\n",
    "#IPythonConsole.ipython_3d = True\n",
    "#from rdkit.Chem import rdDepictor\n",
    "#from rdkit.Chem import rdDistGeom\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def imprconf(mol):\n",
    "    rdForceFieldHelpers.MMFFOptimizeMolecule(mol)\n",
    "    return mol\n",
    "\n",
    "df_sh['confMOLfinal'] = df_sh.confMOL.progress_apply(imprconf)\n",
    "\n",
    "df_sh.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a0bcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "### get atom list\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "\n",
    "def getatseq(mol):\n",
    "    mylist = []\n",
    "    for i, atom in enumerate(mol.GetAtoms()):\n",
    "#        x = mol.GetAtom(i)\n",
    "        mylist.append(atom.GetSymbol())\n",
    "    return mylist\n",
    "\n",
    "df_sh['atomseq'] = df_sh.confMOL.apply(getatseq)\n",
    "\n",
    "#df_sh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc988a4",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5852db43",
   "metadata": {},
   "source": [
    "## Now do the clustering in rdkit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc51e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## cluster conformers\n",
    "# Butina examples\n",
    "# from: https://greglandrum.github.io/rdkit-blog/posts/2023-03-02-clustering-conformers.html\n",
    "# also: https://gist.github.com/tdudgeon/b061dc67f9d879905b50118408c30aac\n",
    "# https://projects.volkamerlab.org/teachopencadd/talktorials/T005_compound_clustering.html\n",
    "# https://github.com/PatWalters/workshop/blob/master/clustering/taylor_butina.ipynb\n",
    "# alternative: DockOnSurf\n",
    "\n",
    "import pandas as pd\n",
    "#from rdkit.Chem import PandasTools, Draw\n",
    "from rdkit import DataStructs\n",
    "from rdkit.ML.Cluster import Butina\n",
    "from rdkit.Chem import rdMolDescriptors as rdmd\n",
    "from rdkit.Chem import Descriptors\n",
    "import seaborn as sns\n",
    "#from IPython.display import HTML\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def cluster_conformers(mol, mode=\"RMSD\", threshold=2.0):\n",
    "    if mode == \"TFD\":\n",
    "        dmat = TorsionFingerprints.GetTFDMatrix(mol)\n",
    "    else:\n",
    "        dmat = AllChem.GetConformerRMSMatrix(mol, prealigned=False)\n",
    "        rms_clusters = Butina.ClusterData(dmat, mol.GetNumConformers(), threshold, isDistData=True, reordering=True)\n",
    "    clustnum = []\n",
    "    conflist = []\n",
    "    for i, value in enumerate(rms_clusters):\n",
    "        for j in rms_clusters[i]:\n",
    "            x = i\n",
    "            clustnum.append(x)\n",
    "            conflist.append(j)\n",
    "    return [rms_clusters, conflist, numclust]\n",
    "\n",
    "df_sh['R5'] = df_sh.confMOL.progress_apply(cluster_conformers)\n",
    "\n",
    "df_sh[[\"templist\",\"conflist\",\"clustnum\"]] = pd.DataFrame(df_sh.R5.to_list(), index=df_sh.index)\n",
    "\n",
    "df_sh.drop(\"R5\",axis=1,inplace=True)\n",
    "\n",
    "df_sh.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17af3a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## write conformer coordinates into pandas frame\n",
    "# https://stackoverflow.com/questions/69564484/how-to-save-rdkit-conformer-object-into-a-sdf-file\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def getatompos(cl, mol):\n",
    "    listoflists = []\n",
    "    for i in cl:\n",
    "        list2 = []\n",
    "        for j, atom in enumerate(mol.GetAtoms()):\n",
    "            positions = mol.GetConformer(i).GetAtomPosition(j)\n",
    "            tup = (positions.x, positions.y, positions.z)\n",
    "            list2.append(tup)\n",
    "        listoflists.append(list2)\n",
    "    return listoflists\n",
    "\n",
    "#df_sh['atompos'] = df_sh[['conflist', 'confMOLfinal']].apply(getatompos, axis=1)\n",
    "df_sh['positions'] = df_sh[['conflist', 'confMOLfinal']].apply(lambda x: getatompos(*x), axis=1)\n",
    "df_sh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7b86d",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb17c9aa",
   "metadata": {},
   "source": [
    "## And, now, the rdkit results need to be uploaded and cleaned:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7648fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make a new dataframe and upload it in one go for atomseq, numclust, and numconf\n",
    "\n",
    "# manipulate atom sequence\n",
    "def listtostring(cl):\n",
    "    values = ''.join(cl)\n",
    "    return values\n",
    "\n",
    "df_sh['atomseqstr'] = df_sh.atomseq.apply(listtostring)\n",
    "\n",
    "# count number of clusters\n",
    "def clustcount(lot):\n",
    "    x = int(len(lot))\n",
    "    return(x)\n",
    "\n",
    "df_sh['numclust'] = df_sh.templist.apply(clustcount)\n",
    "\n",
    "# make sure numconf is an integer\n",
    "def integratize(num):\n",
    "    x = int(num)\n",
    "    return x\n",
    "\n",
    "df_sh['numconf2'] = df_sh.numconf.apply(integratize)\n",
    "\n",
    "\n",
    "df_temp = pd.DataFrame(df_sh[['atomseqstr', 'numconf2', 'numclust']])\n",
    "\n",
    "\n",
    "# upload entire data frame    \n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "try: \n",
    "    sql = \"\"\"REPLACE INTO substituents (atomseq, numconf, numclust) VALUES(%s,%s,%s)\"\"\"\n",
    "    for row in df_temp.values.tolist():\n",
    "        cursor.execute(sql, tuple(row))\n",
    "    connection.commit()\n",
    "    connection.close()\n",
    "    print(\"Query successful\")\n",
    "except Error as err:\n",
    "    print(f\"Error: '{err}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6b7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### make conformers panda dataframe\n",
    "\n",
    "import rdkit\n",
    "from rdkit import Chem\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "out = pd.DataFrame(columns=['R6'])\n",
    "\n",
    "def getcont(confMOLfinal, id_list, atomseqstr):\n",
    "    subs_id = []\n",
    "    for i, atom in enumerate(confMOLfinal.GetConformers()):\n",
    "        subs_id.append(id_list)\n",
    "    atomseq = []\n",
    "    for i, atom in enumerate(confMOLfinal.GetConformers()):\n",
    "        atomseq.append(atomseqstr)\n",
    "    return subs_id, atomseq\n",
    "\n",
    "out['R6'] = pd.DataFrame(df_sh[['confMOLfinal', 'id_list', 'atomseqstr']].progress_apply(lambda x: getcont(*x), axis=1))\n",
    " \n",
    "out[[\"substituent_id\",\"atomseq\"]] = pd.DataFrame(out.R6.to_list(), index=df_sh.index)\n",
    "\n",
    "out.drop(\"R6\",axis=1,inplace=True)\n",
    "\n",
    "out2 = out.explode([\"substituent_id\",\"atomseq\"], ignore_index=True)\n",
    "#out2.head()\n",
    "\n",
    "out3 = pd.DataFrame(df_sh[['atompos','clustnum','conflist']])\n",
    "\n",
    "#out3.head()\n",
    "\n",
    "out4 = out3.explode(['atompos','numclust','conflist'], ignore_index=True)\n",
    "\n",
    "#out4.head()\n",
    "\n",
    "#len(out2.index)\n",
    "#len(out4.index)\n",
    "\n",
    "df_conf = pd.concat([out2.reset_index(drop=True),out4.reset_index(drop=True)], axis=1)\n",
    "\n",
    "df_conf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d4286d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### upload to mysql conformers table\n",
    "\n",
    "import mysql.connector as connection\n",
    "import pandas as pd\n",
    "\n",
    "# change type of data if needed:\n",
    "#improve2 = '''\n",
    "#    SET GLOBAL sql_mode='';\n",
    "#    '''\n",
    "    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve2)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")\n",
    "\n",
    "# correct mistake I made earlier where I uploaded the wrong table into mysql:\n",
    "#improve3 = '''\n",
    "#    DELETE FROM conformers;\n",
    "#    '''\n",
    "    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve3)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")    \n",
    "\n",
    "\n",
    "# change lengths of positions and atoms entrances:\n",
    "#improve4 = '''\n",
    "#    ALTER TABLE conformers MODIFY positions VARCHAR(10000);\n",
    "#    '''\n",
    "    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#cursor.close() \n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve4)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")\n",
    "\n",
    "# change lengths of positions and atoms entrances:\n",
    "#improve5 = '''\n",
    "#    ALTER TABLE conformers MODIFY atoms VARCHAR(200);\n",
    "#    '''\n",
    "    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#cursor.close() \n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve5)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")\n",
    "\n",
    "\n",
    "# get rid of primary key:\n",
    "#improve6 = '''\n",
    "#    ALTER TABLE conformers DROP PRIMARY KEY;;\n",
    "#    '''\n",
    "    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#cursor.close() \n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve6)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")\n",
    "    \n",
    "    \n",
    "\n",
    "# upload entire data frame    \n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "try: \n",
    "    sql = \"\"\"REPLACE INTO conformers (substituent_id, atoms, positions, cluster_no, conformer_num) VALUES(%s,%s,%s,%s,%s)\"\"\"\n",
    "    for row in df_conf.values.tolist():\n",
    "        cursor.execute(sql, tuple(row))\n",
    "    connection.commit()\n",
    "    connection.close()\n",
    "    print(\"Query successful\")\n",
    "except Error as err:\n",
    "    print(f\"Error: '{err}'\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7351c705",
   "metadata": {},
   "outputs": [],
   "source": [
    "### clean-up\n",
    "\n",
    "import pandas\n",
    "import rdkit\n",
    "\n",
    "##################################################################\n",
    "#### work on it\n",
    "#####################################################################\n",
    "df_conf.to_csv('out.csv')\n",
    "\n",
    "lst = [df_sh,  initial_df, out, out2, out3, out4, df_conf]\n",
    "del lst\n",
    "\n",
    "\n",
    "\n",
    "#! conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c25ef9e",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797de65",
   "metadata": {},
   "source": [
    "## switch to ase chemistry for energy computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a4cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### withdraw data from sql\n",
    "\n",
    "# ! conda activate rdkit \n",
    "\n",
    "import mysql.connector as connection\n",
    "import pandas as pd\n",
    "\n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "try:\n",
    "    mydb = connection.connect(host=\"localhost\", database = db,user=\"root\", passwd = pw,use_pure=True)\n",
    "    query = \"Select * from conformers;\"\n",
    "    result_dataFrame = pd.read_sql(query,mydb)\n",
    "    mydb.close() #close the connectionexcept Exception as e:\n",
    "\n",
    "except Exception as e:\n",
    "    mydb.close()\n",
    "    print(str(e))\n",
    "\n",
    "len(result_dataFrame.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9222f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create ase atoms object\n",
    "\n",
    "from ase import Atom, Atoms\n",
    "from ase.io import read\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "# \n",
    "def strtofloat(str1):\n",
    "#    str2 = str1[-1:-1]\n",
    "    str2 = str1.replace(\"[\", \"\")\n",
    "    str3 = str2.replace(\"]\", \"\")\n",
    "    return eval( \"[%s]\" % str3 )\n",
    "\n",
    "result_dataFrame['positions2'] = result_dataFrame.atompos.progress_apply(strtofloat)\n",
    "\n",
    "#\n",
    "def aseatom(list1, list2):\n",
    "    seq = list1\n",
    "    pos = list2\n",
    "    a = Atoms(seq, pos)\n",
    "    return a\n",
    "\n",
    "result_dataFrame['aseobj'] = result_dataFrame[['atomseq', 'positions']].progress_apply(lambda x: aseatom(*x), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292a5ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### calculate point energy for each conformer\n",
    "\n",
    "import ase\n",
    "from ase import Atom, Atoms\n",
    "from ase.io import read\n",
    "from ase.visualize import view\n",
    "from ase.calculators.lj import LennardJones\n",
    "from ase.optimize import BFGS\n",
    "from ase.units import Hartree\n",
    "import pandas as pd\n",
    "from parallel_pandas import ParallelPandas\n",
    "from pandarallel import pandarallel\n",
    "\n",
    "pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "#initialize parallel-pandas\n",
    "#ParallelPandas.initialize(n_cpu=4, split_factor=4, disable_pr_bar=False)\n",
    "#\n",
    "def calcenergy(a):\n",
    "    import ase\n",
    "    from ase import Atom, Atoms\n",
    "    from ase.calculators.lj import LennardJones\n",
    "    from ase.units import Hartree\n",
    "    a.set_calculator(LennardJones())\n",
    "    E_pot_emt = a.get_potential_energy()\n",
    "    return E_pot_emt\n",
    "\n",
    "result_dataFrame['energies'] = result_dataFrame.aseobj.parallel_apply(calcenergy)\n",
    "\n",
    "results2 = result_dataFrame['energies'].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3742824f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### add energy values to conformers table - alternative method\n",
    "\n",
    "# change type of data if needed:\n",
    "#improve8 = '''\n",
    "#    ALTER TABLE conformers MODIFY energies VARCHAR(1000);\n",
    "#    '''\n",
    "#    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve8)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")\n",
    "\n",
    "\n",
    "# change sql mode:\n",
    "#improve9 = '''\n",
    "#    SET GLOBAL sql_mode='';\n",
    "#    '''\n",
    "    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve9)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")\n",
    "\n",
    "# upload entire data frame column    \n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "try: \n",
    "    sql = \"\"\"INSERT INTO conformers (energies) VALUES(%s)\"\"\"\n",
    "    for row in results2.values.tolist():      # modify to the name of your actual table -> make sure you pass only one column\n",
    "        cursor.execute(sql, tuple(row))\n",
    "    connection.commit()\n",
    "    connection.close()\n",
    "    print(\"Query successful\")\n",
    "except Error as err:\n",
    "    print(f\"Error: '{err}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b49e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### deactivate and clean-up\n",
    "\n",
    "#! conda deactivate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4e4d63",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e765e",
   "metadata": {},
   "source": [
    "## find min and average energy conformers in SQL and populate cluster table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fce263c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add new column with cluster ID in conformers table\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "# change sql mode:\n",
    "#improve9 = '''\n",
    "#    SET GLOBAL sql_mode='';\n",
    "#    '''\n",
    "    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve9)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")\n",
    "    \n",
    "\n",
    "# get rid off primary key:\n",
    "#improve10 = '''\n",
    "#    alter table conformers drop primary key;\n",
    "#    '''\n",
    "    \n",
    "\n",
    "#pw = \n",
    "#db = 'substituents'\n",
    "\n",
    "#connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "#cursor = connection.cursor()\n",
    "#try:\n",
    "#    cursor.execute(improve10)\n",
    "#    connection.commit()\n",
    "#    print(\"Query successful\")\n",
    "#except Error as err:\n",
    "#    print(f\"Error: '{err}'\")\n",
    "\n",
    "# do the actual operations\n",
    "\n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db) # Connect to the Database\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# queries:\n",
    "\n",
    "qu_1 = '''ALTER TABLE conformers ADD COLUMN clustID VARCHAR(100);'''\n",
    "qu_1B = '''UPDATE conformers SET clustID = CONCAT(substituent_id, '-', cluster_no);'''\n",
    "qu_2 = '''ALTER TABLE conformers DROP COLUMN cluster_no'''\n",
    "qu_3 = '''REPLACE INTO clusters (clustID) SELECT DISTINCT clustID FROM conformers'''\n",
    "\n",
    "#execute_query(connection, qu_1) # Execute our defined query\n",
    "#execute_query(connection, qu_1B)\n",
    "#execute_query(connection, qu_2)\n",
    "#execute_query(connection, qu_3)\n",
    "execute_query(connection, '''COMMIT''')\n",
    "# done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23a36b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find member with minimum and average energy\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db) # Connect to the Database\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# queries:\n",
    "\n",
    "qu_4 = '''INSERT INTO substituents (lowest_energy) SELECT MIN(energies) FROM conformers GROUP BY clustID;'''\n",
    "qu_5 = '''INSERT INTO clusters (clust_le) SELECT MIN(energies) FROM conformers GROUP BY clustID;'''\n",
    "qu_6 = '''INSERT INTO clusters (clust_ae) SELECT AVG(energies) FROM conformers GROUP BY clustID;'''\n",
    "\n",
    "#execute_query(connection, '''SET autocommit = ON;''')\n",
    "execute_query(connection, qu_4) # Execute our defined query\n",
    "#execute_query(connection, qu_5)\n",
    "#execute_query(connection, qu_6)\n",
    "#execute_query(connection, '''SET autocommit = OFF;''')\n",
    "\n",
    "# note: mysql> show processlist; -> kill \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e8e58d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### find the median energy\n",
    "# the code was generated with ChatGPT\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "import pandas as pd\n",
    "\n",
    "# get rid of primary key:\n",
    "improve6 = '''\n",
    "    ALTER TABLE clusters DROP PRIMARY KEY;;\n",
    "    '''\n",
    "    \n",
    "\n",
    "pw =  \n",
    "db = 'substituents'\n",
    "\n",
    "#cursor.close() \n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db)\n",
    "\n",
    "cursor = connection.cursor()\n",
    "try:\n",
    "    cursor.execute(improve6)\n",
    "    connection.commit()\n",
    "    print(\"Query successful\")\n",
    "except Error as err:\n",
    "    print(f\"Error: '{err}'\")\n",
    "    \n",
    "    \n",
    "\n",
    "pw = \n",
    "db = 'substituents'\n",
    "\n",
    "connection = create_db_connection(\"localhost\", \"root\", pw, db) # Connect to the Database\n",
    "\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# queries:\n",
    "\n",
    "qu_7A = '''SET SESSION group_concat_max_len = 1000000;'''\n",
    "qu_7 = '''\n",
    "    CREATE TEMPORARY TABLE temp_median_table AS\n",
    "    SELECT \n",
    "      clustID,\n",
    "      (CASE \n",
    "        WHEN COUNT(energies) % 2 = 1 THEN \n",
    "          SUBSTRING_INDEX(SUBSTRING_INDEX(GROUP_CONCAT(energies ORDER BY energies), ',', COUNT(energies) / 2 + 1), ',', -1)\n",
    "        ELSE\n",
    "          (SUBSTRING_INDEX(SUBSTRING_INDEX(GROUP_CONCAT(energies ORDER BY energies), ',', COUNT(energies) / 2), ',', -1) +\n",
    "           SUBSTRING_INDEX(SUBSTRING_INDEX(GROUP_CONCAT(energies ORDER BY energies), ',', COUNT(energies) / 2 + 1), ',', -1)) / 2\n",
    "        END\n",
    "      ) AS median_value\n",
    "    FROM conformers\n",
    "    GROUP BY clustID;\n",
    "    '''\n",
    "qu_8 = '''INSERT INTO clusters (clustID, median_value) SELECT clustID, median_value FROM temp_median_table;'''\n",
    "\n",
    "qu_9 = '''\n",
    "    INSERT INTO clusters (clustID, clust_me)\n",
    "    SELECT clustID, \n",
    "           ROUND(\n",
    "             AVG(energies) + \n",
    "             IF(COUNT(energies) % 2 = 1, 0, \n",
    "                IF(COUNT(energies) = 0, 0, \n",
    "                   IF(MOD(COUNT(energies), 2) = 0, \n",
    "                      (SUBSTRING_INDEX(\n",
    "                        SUBSTRING_INDEX(\n",
    "                          GROUP_CONCAT(energies ORDER BY energies), \n",
    "                        ',', \n",
    "                        COUNT(energies) / 2 + 1), \n",
    "                      ',', \n",
    "                      -1) + \n",
    "                      SUBSTRING_INDEX(\n",
    "                        SUBSTRING_INDEX(\n",
    "                          GROUP_CONCAT(energies ORDER BY energies), \n",
    "                        ',', \n",
    "                        COUNT(energies) / 2), \n",
    "                      ',', \n",
    "                      -1)) / 2, \n",
    "                    SUBSTRING_INDEX(\n",
    "                      SUBSTRING_INDEX(\n",
    "                        GROUP_CONCAT(energies ORDER BY energies), \n",
    "                      ',', \n",
    "                      COUNT(energies) / 2 + 1), \n",
    "                    ',', \n",
    "                    -1))))\n",
    "            , 2) AS clust_me\n",
    "    FROM conformers\n",
    "    GROUP BY clustID;\n",
    "    '''\n",
    "\n",
    "#execute_query(connection, qu_7A)\n",
    "#execute_query(connection, qu_7)\n",
    "#execute_query(connection, qu_8)\n",
    "\n",
    "# as temporary tables get deleted during connections - let's make it all in one go\n",
    "\n",
    "execute_query(connection, qu_9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7db49ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! conda deactivate"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
